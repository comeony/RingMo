base_config: [
  '../base/context/semi_moe_mode_2nodes.yaml',
  '../base/datasets/pretrain_dataset.yaml',
  '../base/models/simmim_vit_base_p16.yaml',
  '../base/schedules/default_schedule.yaml',
  '../base/runner/runner.yaml',
  '../base/modelarts/aicc.yaml',
  '../base/__base__.yaml']

arch: "simmim"
use_parallel: False
profile: False
auto_tune: True  # dataset performance
filepath_prefix: "./autotune"
autotune_per_step: 10

#parallel:
#  strategy_ckpt_save_file: "./ckpt_strategy.ckpt"
#  strategy_ckpt_load_file:

moe_config: # 参考 mindspore.nn.transformer.moe
    expert_num: 32  #  专家数量  examples: 32
    capacity_factor: 1.05  # token容量 候选token比例
    aux_loss_factor: 0.0001  # moe loss 占比
    num_experts_chosen: 1  # token choose experts num

pretrain_dataset:
  data_type: "mindrecord"
  data_path: "/data/mae_15w_record_2"
  image_ids: "aircas.mindrecord00"
  input_columns: [ "image" ]
  output_columns: [ "image", "mask" ]
  column_order: [ "image", "mask" ]

train_config:
  epoch: 800
  batch_size: 128
  image_size: 224
  per_epoch_size: 0

# optimizer
optimizer:
  optim_name: "AdamW"
  beta1: 0.9
  beta2: 0.999
  eps: 0.00000001 # 1e-8
  weight_decay: 0.05

# lr sechdule
lr_schedule:
  lr_type: "warmup_cosine_decay_simmim"
  base_lr: 0.0001
  min_lr: 0.0000005
  warmup_lr: 0.0000005
  warmup_epochs: 20

aicc_config:
  obs_path: "Input your obs path if code is running on modelarts else invalid."
  upload_frequence: 1
  keep_last: False
